{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jroady_rfahrn_tm_ex05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "3Sup6WXLW-NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install emoji\n",
        "! pip install pyarabic\n",
        "! pip install transformers"
      ],
      "metadata": {
        "id": "I-uHeaF8XN-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0aa7f8d-0fc9-4c1d-e026-b656aa27c899"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.7/dist-packages (0.6.15)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/rfahrn/Shared_Task.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9fy7pyiX-8r",
        "outputId": "7a8a2850-be77-4c0b-fb71-7b89c57da59b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Shared_Task' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import unicodedata\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pyarabic.araby as ar\n",
        "import pickle\n",
        "import string\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Z7y8PacKWVWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-mini-arabic\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cnCqwexiWVWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd1cf34-9fff-4cd1-8861-991cb8bd0d37"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "train = pd.read_csv('Shared_Task/data/offenseval-ar-training-v1.tsv', sep='\\t', encoding='utf-8')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nJM1mgRNWVWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preview data"
      ],
      "metadata": {
        "id": "ngu1Lp3IaIbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(10)"
      ],
      "metadata": {
        "id": "57aoLZH8aF3X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "fdb8339e-a2d0-4e11-fc68-1cce88bce560"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              tweet subtask_a\n",
              "0   1  Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...       NOT\n",
              "1   2            ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡       NOT\n",
              "2   3  RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø£Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...       OFF\n",
              "3   4  RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...       NOT\n",
              "4   5          ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø£Ù‡Ù… ÙŠØ§ Ø¥Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø£ÙƒÙˆÙ† ğŸ¼       NOT\n",
              "5   6  @USER Ø§Ø®Ø® ÙŠØ§ Ù‚Ù„Ø¨Ø¨ÙŠ ÙŠØ§ Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡ ğŸ˜©ğŸ˜­â™¥ï¸ Ù…ØªØ¹Ù‡ Ø¹Ù„Ù‰ Ø¨Ùƒ...       NOT\n",
              "6   7  ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ø²ÙˆÙ„ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ Ø£Ø«Ø¨Øª Ø£Ù†Ù‡ Ø³Ø§Ø¨Ù‚ Ø¨Ø§Ù„ØªØ­Ø¶Ù‘Ø± Ø¹Ù†...       NOT\n",
              "7   8  RT @USER: Ø¬Ø§Ù„Ø³ Ø£Ø³Ù…Ø¹ Ø£Ø­Ù…Ø¯ Ù‚Ø§Ø³Ù… ÙŠØºÙ†ÙŠ: \"Ø£Ø­Ø¨Ùƒ Ù…Ù† Ùƒ...       NOT\n",
              "8   9             ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙŠØ§ Ù…ØºÙ„Ø§Ùƒ<LF>ÙˆØ¨Ø¹ÙŠÙ†ÙŠ ÙŠØ§ Ù…Ø­Ù„Ø§Ùƒ ..       NOT\n",
              "9  10  ÙŠØ§ Ø§Ù„ØªØ§Ø¬ Ø¹ Ø§Ù„Ø±Ø§Ø³ ÙŠØ§ Ø§Ù„Ø³Ø§Ø¯Ø©<LF>ÙŠØ§ Ù…Ø§Ù„Ùƒ Ø§Ù„Ø±ÙˆØ­ ÙˆØ±...       NOT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3207be65-91a0-4d16-afe9-4a34d5132d6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø£Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø£Ù‡Ù… ÙŠØ§ Ø¥Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø£ÙƒÙˆÙ† ğŸ¼</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>@USER Ø§Ø®Ø® ÙŠØ§ Ù‚Ù„Ø¨Ø¨ÙŠ ÙŠØ§ Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡ ğŸ˜©ğŸ˜­â™¥ï¸ Ù…ØªØ¹Ù‡ Ø¹Ù„Ù‰ Ø¨Ùƒ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ø²ÙˆÙ„ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ Ø£Ø«Ø¨Øª Ø£Ù†Ù‡ Ø³Ø§Ø¨Ù‚ Ø¨Ø§Ù„ØªØ­Ø¶Ù‘Ø± Ø¹Ù†...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>RT @USER: Ø¬Ø§Ù„Ø³ Ø£Ø³Ù…Ø¹ Ø£Ø­Ù…Ø¯ Ù‚Ø§Ø³Ù… ÙŠØºÙ†ÙŠ: \"Ø£Ø­Ø¨Ùƒ Ù…Ù† Ùƒ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙŠØ§ Ù…ØºÙ„Ø§Ùƒ&lt;LF&gt;ÙˆØ¨Ø¹ÙŠÙ†ÙŠ ÙŠØ§ Ù…Ø­Ù„Ø§Ùƒ ..</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>ÙŠØ§ Ø§Ù„ØªØ§Ø¬ Ø¹ Ø§Ù„Ø±Ø§Ø³ ÙŠØ§ Ø§Ù„Ø³Ø§Ø¯Ø©&lt;LF&gt;ÙŠØ§ Ù…Ø§Ù„Ùƒ Ø§Ù„Ø±ÙˆØ­ ÙˆØ±...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3207be65-91a0-4d16-afe9-4a34d5132d6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3207be65-91a0-4d16-afe9-4a34d5132d6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3207be65-91a0-4d16-afe9-4a34d5132d6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(train.subtask_a)\n",
        "plt.title('Count NOT/OFF')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "4pLDsSenaPbM",
        "outputId": "c4c2721f-fb2b-46b0-fad3-b25cff4fd968"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Count NOT/OFF')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are much more non-offensive than offensive tweets - a common issue in HSD data. Transformers tend to perform better with balanced datasets."
      ],
      "metadata": {
        "id": "obXvw4RsXcaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "d7Yox42IXndS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jessica"
      ],
      "metadata": {
        "id": "ZXXjgxQhXv-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PUNCTUATION = '''`Ã·Ã—Ø›<>_()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
        "\n",
        "\n",
        "# def remove_emoji(tweet):\n",
        "#     return emoji.get_emoji_regexp().sub(u'', tweet)\n",
        "\n",
        "\n",
        "# def remove_lf(tweet):\n",
        "#     \"\"\" This string appears in many tweets and appears to serve no linguistic function. \"\"\"\n",
        "#     return tweet.replace('<LF>', ' ')\n",
        "\n",
        "\n",
        "# def remove_repeat_chars(tweet):\n",
        "#     \"\"\" Removes only non-digit, non-punctuation characters that are repeated more than once, since double characters can appear in correct spelling. \"\"\"\n",
        "#     new = ''\n",
        "\n",
        "#     for char in tweet:\n",
        "#         if char.isdigit():\n",
        "#             new += char\n",
        "#         elif char in PUNCTUATION:\n",
        "#             new += char\n",
        "#         else:\n",
        "#             if not new.endswith(char+char):\n",
        "#                 new += char\n",
        "\n",
        "#     return new\n",
        "\n",
        "\n",
        "# def remove_diacritics(tweet):\n",
        "#     \"\"\" Diacritics in Arabic serve no semantic or syntactic function. \"\"\"\n",
        "#     tweet = ar.strip_tashkeel(tweet)\n",
        "#     tweet = ar.strip_tatweel(tweet)\n",
        "\n",
        "#     tweet = tweet.replace(\"Ø¢\", \"Ø§\")\n",
        "#     tweet = tweet.replace(\"Ø¥\", \"Ø§\")\n",
        "#     tweet = tweet.replace(\"Ø£\", \"Ø§\")\n",
        "#     tweet = tweet.replace(\"Ø¤\", \"Ùˆ\")\n",
        "#     tweet = tweet.replace(\"Ø¦\", \"ÙŠ\")\n",
        "\n",
        "#     return tweet\n",
        "\n",
        "\n",
        "# def normalise_encoding(tweet):\n",
        "#     tweet = re.sub(r'&amp;', '&', tweet)\n",
        "#     tweet = unicodedata.normalize('NFC', tweet)\n",
        "#     return tweet\n",
        "\n",
        "\n",
        "# train['tweet'] = train['tweet'].apply(remove_lf)\n",
        "# train['tweet'] = train['tweet'].apply(remove_repeat_chars)\n",
        "# train['tweet'] = train['tweet'].apply(remove_diacritics)\n",
        "# train['tweet'] = train['tweet'].apply(normalise_encoding)\n",
        "# # Convert to binary values\n",
        "# train['subtask_a'] = train['subtask_a'].apply(lambda x: 1 if x=='NOT' else 0)\n",
        "\n",
        "# # Make one df with emoji and one without to compare performance later\n",
        "# train_no_emoji = train\n",
        "# train_no_emoji['tweet'] = train_no_emoji['tweet'].apply(remove_emoji)\n",
        "\n",
        "# dfs = [train, train_no_emoji]\n",
        "\n",
        "# train.head(10)"
      ],
      "metadata": {
        "id": "SOfC-ci8XXlO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rebecka"
      ],
      "metadata": {
        "id": "8neFtMHhXzdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Preprocessing Arabic Tweets\n",
        "# punctuations = '''`Ã·Ã—Ø›<>_()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€''' + string.punctuation\n",
        "\n",
        "# arabic_diacritics = re.compile(\"\"\"\n",
        "#                              Ù‘    | # Shadda\n",
        "#                              Ù    | # Fatha\n",
        "#                              Ù‹    | # Tanwin Fath\n",
        "#                              Ù    | # Damma\n",
        "#                              ÙŒ    | # Tanwin Damm\n",
        "#                              Ù    | # Kasra\n",
        "#                              Ù    | # Tanwin Kasr\n",
        "#                              Ù’    | # Sukun\n",
        "#                              Ù€     # Tatwil/Kashida\n",
        "#                          \"\"\", re.VERBOSE)\n",
        "\n",
        "\n",
        "# def preprocess(text):\n",
        "#     #remove punctuations\n",
        "#     translator = str.maketrans('', '', punctuations)\n",
        "#     text = text.translate(translator)\n",
        "#     # Normalize unicode encoding\n",
        "#     text = unicodedata.normalize('NFC',text)\n",
        "\n",
        "#     # Remove '@name'\n",
        "#     text = re.sub(r'(@.*?)[\\s]', '', text)\n",
        "\n",
        "#     # Replace '&amp;' with '&'\n",
        "#     text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "#     # Remove trailing whitespace\n",
        "#     text = re.sub(r'\\s+', '', text).strip()\n",
        "    \n",
        "#     #Remove URLs\n",
        "#     text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "\n",
        "#     # remove Tashkeel\n",
        "#     text = re.sub(arabic_diacritics, '', text)\n",
        "    \n",
        "#     #remove longation\n",
        "#     text = re.sub(\"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\", text)\n",
        "#     text = re.sub(\"Ù‰\", \"ÙŠ\", text)\n",
        "#     text = re.sub(\"Ø¤\", \"Ø¡\", text)\n",
        "#     text = re.sub(\"Ø¦\", \"Ø¡\", text)\n",
        "#     text = re.sub(\"Ø©\", \"Ù‡\", text)\n",
        "#     text = re.sub(\"Ú¯\", \"Ùƒ\", text)\n",
        "\n",
        "#     text = ' '.join(word for word in text.split())\n",
        "\n",
        "#     return text\n",
        "  \n",
        "# #train['tweet'] = train['tweet'].apply(preprocess)\n",
        "\n",
        "# # convert off 1 and not 0\n",
        "# train['subtask_a']=train['subtask_a'].apply(lambda x: 1 if x=='NOT' else 0)\n",
        "\n",
        "# train.head(10)"
      ],
      "metadata": {
        "id": "0CKFGXpKX1nj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "0Hou2LZsbDIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PUNCTUATION = '''`Ã·Ã—Ø›<>_()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
        "\n",
        "\n",
        "def remove_emoji(tweet):\n",
        "  return emoji.get_emoji_regexp().sub(u' ', tweet)\n",
        "\n",
        "\n",
        "def remove_lf(tweet):\n",
        "  \"\"\" This string appears in many tweets and appears to serve no linguistic function. \"\"\"\n",
        "  return tweet.replace('<LF>', ' ')\n",
        "  \n",
        "\n",
        "def remove_repeat_chars(tweet):\n",
        "  \"\"\" Removes only non-digit, non-punctuation characters that are repeated more than once, since double characters can appear in correct spelling. \"\"\"\n",
        "  new = ''\n",
        "\n",
        "  for char in tweet:\n",
        "      if char.isdigit():\n",
        "          new += char\n",
        "      elif char in PUNCTUATION:\n",
        "          new += char\n",
        "      else:\n",
        "          if not new.endswith(char+char):\n",
        "              new += char\n",
        "\n",
        "  return new\n",
        "\n",
        "\n",
        "def normalise_encoding(tweet):\n",
        "  tweet = re.sub(r'&amp;', '&', tweet)\n",
        "  # tweet = unicodedata.normalize('NFC', tweet)\n",
        "  tweet = re.sub(r'\\\\u....', ' ', tweet)  # Remove the \\uXXXX that ends up replacing left-to-right space characters\n",
        "  tweet = re.sub(r'\\\\xa0', ' ', tweet)  # Remove the \\xa0 that ends up replacing NBSP characters\n",
        "  return tweet\n",
        "\n",
        "\n",
        "def remove_diacritics(tweet):\n",
        "  \"\"\" Diacritics in Arabic only aid pronunciation, and serve no semantic or syntactic function. \"\"\"\n",
        "  tweet = ar.strip_tashkeel(tweet)\n",
        "  tweet = ar.strip_tatweel(tweet)\n",
        "\n",
        "  tweet = tweet.replace(\"Ø¢\", \"Ø§\")\n",
        "  tweet = tweet.replace(\"Ø¥\", \"Ø§\")\n",
        "  tweet = tweet.replace(\"Ø£\", \"Ø§\")\n",
        "  tweet = tweet.replace(\"Ø¤\", \"Ùˆ\")\n",
        "  tweet = tweet.replace(\"Ø¦\", \"ÙŠ\")\n",
        "\n",
        "  return tweet\n",
        "\n",
        "\n",
        "train['tweet'] = train['tweet'].apply(normalise_encoding)\n",
        "train['tweet'] = train['tweet'].apply(remove_lf)\n",
        "train['tweet'] = train['tweet'].apply(remove_diacritics)\n",
        "train['tweet'] = train['tweet'].apply(remove_repeat_chars)\n",
        "\n",
        "# Convert to binary values\n",
        "train['subtask_a'] = train['subtask_a'].apply(lambda x: 1 if x=='NOT' else 0)\n",
        "\n",
        "# Make one df with emoji and one without to compare performance later\n",
        "train_no_emoji = train\n",
        "train_no_emoji['tweet'] = train_no_emoji['tweet'].apply(remove_emoji)\n",
        "\n",
        "dfs = [train, train_no_emoji]"
      ],
      "metadata": {
        "id": "xz6g-O4wbCvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33a108c-a68a-4989-94bb-3170c21b54a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_no_emoji.head(10)"
      ],
      "metadata": {
        "id": "ra89z0xLdASD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "6212be2a-4ad4-4164-e63a-3000ab55c948"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              tweet  subtask_a\n",
              "0   1  Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...          1\n",
              "1   2            ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡          1\n",
              "2   3  RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø§Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...          0\n",
              "3   4  RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...          1\n",
              "4   5          ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø§Ù‡Ù… ÙŠØ§ Ø§Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø§ÙƒÙˆÙ†            1\n",
              "5   6  @USER Ø§Ø®Ø® ÙŠØ§ Ù‚Ù„Ø¨Ø¨ÙŠ ÙŠØ§ Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡     Ù…ØªØ¹Ù‡ Ø¹Ù„Ù‰ Ø¨ÙƒØ§...          1\n",
              "6   7  ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ø²ÙˆÙ„ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ Ø§Ø«Ø¨Øª Ø§Ù†Ù‡ Ø³Ø§Ø¨Ù‚ Ø¨Ø§Ù„ØªØ­Ø¶Ø± Ø¹Ù† ...          1\n",
              "7   8  RT @USER: Ø¬Ø§Ù„Ø³ Ø§Ø³Ù…Ø¹ Ø§Ø­Ù…Ø¯ Ù‚Ø§Ø³Ù… ÙŠØºÙ†ÙŠ: \"Ø§Ø­Ø¨Ùƒ Ù…Ù† Ùƒ...          1\n",
              "8   9                ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙŠØ§ Ù…ØºÙ„Ø§Ùƒ ÙˆØ¨Ø¹ÙŠÙ†ÙŠ ÙŠØ§ Ù…Ø­Ù„Ø§Ùƒ ..          1\n",
              "9  10  ÙŠØ§ Ø§Ù„ØªØ§Ø¬ Ø¹ Ø§Ù„Ø±Ø§Ø³ ÙŠØ§ Ø§Ù„Ø³Ø§Ø¯Ø© ÙŠØ§ Ù…Ø§Ù„Ùƒ Ø§Ù„Ø±ÙˆØ­ ÙˆØ±Ø§Ø¹ÙŠÙ‡Ø§           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20f0786f-aca4-4098-8a83-f2b4ef1d89aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø§Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø§Ù‡Ù… ÙŠØ§ Ø§Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø§ÙƒÙˆÙ†</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>@USER Ø§Ø®Ø® ÙŠØ§ Ù‚Ù„Ø¨Ø¨ÙŠ ÙŠØ§ Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡     Ù…ØªØ¹Ù‡ Ø¹Ù„Ù‰ Ø¨ÙƒØ§...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ø²ÙˆÙ„ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ Ø§Ø«Ø¨Øª Ø§Ù†Ù‡ Ø³Ø§Ø¨Ù‚ Ø¨Ø§Ù„ØªØ­Ø¶Ø± Ø¹Ù† ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>RT @USER: Ø¬Ø§Ù„Ø³ Ø§Ø³Ù…Ø¹ Ø§Ø­Ù…Ø¯ Ù‚Ø§Ø³Ù… ÙŠØºÙ†ÙŠ: \"Ø§Ø­Ø¨Ùƒ Ù…Ù† Ùƒ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙŠØ§ Ù…ØºÙ„Ø§Ùƒ ÙˆØ¨Ø¹ÙŠÙ†ÙŠ ÙŠØ§ Ù…Ø­Ù„Ø§Ùƒ ..</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>ÙŠØ§ Ø§Ù„ØªØ§Ø¬ Ø¹ Ø§Ù„Ø±Ø§Ø³ ÙŠØ§ Ø§Ù„Ø³Ø§Ø¯Ø© ÙŠØ§ Ù…Ø§Ù„Ùƒ Ø§Ù„Ø±ÙˆØ­ ÙˆØ±Ø§Ø¹ÙŠÙ‡Ø§</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20f0786f-aca4-4098-8a83-f2b4ef1d89aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20f0786f-aca4-4098-8a83-f2b4ef1d89aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20f0786f-aca4-4098-8a83-f2b4ef1d89aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_no_emoji.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "uIH73TGYjMFo",
        "outputId": "8d884450-60e0-4a36-def6-2cd6c5ebcf3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              tweet  subtask_a\n",
              "0   1  Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...          1\n",
              "1   2            ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡          1\n",
              "2   3  RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø§Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...          0\n",
              "3   4  RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...          1\n",
              "4   5          ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø§Ù‡Ù… ÙŠØ§ Ø§Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø§ÙƒÙˆÙ†            1\n",
              "5   6  @USER Ø§Ø®Ø® ÙŠØ§ Ù‚Ù„Ø¨Ø¨ÙŠ ÙŠØ§ Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡     Ù…ØªØ¹Ù‡ Ø¹Ù„Ù‰ Ø¨ÙƒØ§...          1\n",
              "6   7  ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ø²ÙˆÙ„ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ Ø§Ø«Ø¨Øª Ø§Ù†Ù‡ Ø³Ø§Ø¨Ù‚ Ø¨Ø§Ù„ØªØ­Ø¶Ø± Ø¹Ù† ...          1\n",
              "7   8  RT @USER: Ø¬Ø§Ù„Ø³ Ø§Ø³Ù…Ø¹ Ø§Ø­Ù…Ø¯ Ù‚Ø§Ø³Ù… ÙŠØºÙ†ÙŠ: \"Ø§Ø­Ø¨Ùƒ Ù…Ù† Ùƒ...          1\n",
              "8   9                ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙŠØ§ Ù…ØºÙ„Ø§Ùƒ ÙˆØ¨Ø¹ÙŠÙ†ÙŠ ÙŠØ§ Ù…Ø­Ù„Ø§Ùƒ ..          1\n",
              "9  10  ÙŠØ§ Ø§Ù„ØªØ§Ø¬ Ø¹ Ø§Ù„Ø±Ø§Ø³ ÙŠØ§ Ø§Ù„Ø³Ø§Ø¯Ø© ÙŠØ§ Ù…Ø§Ù„Ùƒ Ø§Ù„Ø±ÙˆØ­ ÙˆØ±Ø§Ø¹ÙŠÙ‡Ø§           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b70a9f97-4d0d-468d-87fe-e49fd153e704\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙŠØ§Ø±Ø¨ ÙÙˆØ² Ù…Ù‡Ù… ÙŠØ§ Ø²Ù…Ø§Ù„Ùƒ.. ÙƒÙ„ Ø§Ù„Ø¯Ø¹Ù… Ù„ÙŠÙƒÙ…...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ ÙˆØ§Ø­Ø¯ ÙŠØ§ Ø§Ø­Ø¯ Ø¨Ø­Ù‚ ÙŠÙˆÙ… Ø§Ù„Ø§Ø­Ø¯ Ø§...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>RT @USER: #Ù‡ÙˆØ§_Ø§Ù„Ø­Ø±ÙŠØ© ÙŠØ§ ÙˆØ¬Ø¹ Ù‚Ù„Ø¨ÙŠ Ø¹Ù„ÙŠÙƒÙŠ ÙŠØ§ Ø§Ù…ÙŠ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø§Ù‡Ù… ÙŠØ§ Ø§Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø§ÙƒÙˆÙ†</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>@USER Ø§Ø®Ø® ÙŠØ§ Ù‚Ù„Ø¨Ø¨ÙŠ ÙŠØ§ Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡     Ù…ØªØ¹Ù‡ Ø¹Ù„Ù‰ Ø¨ÙƒØ§...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ø²ÙˆÙ„ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ Ø§Ø«Ø¨Øª Ø§Ù†Ù‡ Ø³Ø§Ø¨Ù‚ Ø¨Ø§Ù„ØªØ­Ø¶Ø± Ø¹Ù† ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>RT @USER: Ø¬Ø§Ù„Ø³ Ø§Ø³Ù…Ø¹ Ø§Ø­Ù…Ø¯ Ù‚Ø§Ø³Ù… ÙŠØºÙ†ÙŠ: \"Ø§Ø­Ø¨Ùƒ Ù…Ù† Ùƒ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙŠØ§ Ù…ØºÙ„Ø§Ùƒ ÙˆØ¨Ø¹ÙŠÙ†ÙŠ ÙŠØ§ Ù…Ø­Ù„Ø§Ùƒ ..</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>ÙŠØ§ Ø§Ù„ØªØ§Ø¬ Ø¹ Ø§Ù„Ø±Ø§Ø³ ÙŠØ§ Ø§Ù„Ø³Ø§Ø¯Ø© ÙŠØ§ Ù…Ø§Ù„Ùƒ Ø§Ù„Ø±ÙˆØ­ ÙˆØ±Ø§Ø¹ÙŠÙ‡Ø§</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b70a9f97-4d0d-468d-87fe-e49fd153e704')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b70a9f97-4d0d-468d-87fe-e49fd153e704 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b70a9f97-4d0d-468d-87fe-e49fd153e704');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity check"
      ],
      "metadata": {
        "id": "qPDFE5AdjiO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_chars(tweet):\n",
        "    return len(tweet)\n",
        "\n",
        "\n",
        "for df in dfs:\n",
        "    df['char_count'] = df['tweet'].apply(count_chars)\n",
        "\n",
        "train_no_emoji.sort_values(by='char_count', ascending=[0]).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "9s43pncCjkH3",
        "outputId": "b0e392da-d3c4-42d3-e22e-feb9329ae9d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              tweet  subtask_a  \\\n",
              "2922  2946   Ù…Ù† Ø§Ù„Ù…Ø¸Ø§Ù‡Ø± Ø§Ù„Ù…ÙˆØ³ÙÙ‡ Ø§Ù† Ø§Ù„Ø§Ø¨ ÙˆØ§Ù„Ø§Ù…  ÙŠÙ‚Ø¹Ø¯ÙˆÙ† ÙŠØªÙ‡Ø§...          1   \n",
              "6062  6160   Ø¬Ø¯Ù‡ Ø§Ù„Ø­Ø¨ ØŒØŒ Ø¬Ø¯Ù‡ ÙŠØ§ Ù…Ù†ØªÙ‡Ù‰ ÙƒÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… ÙŠØ§ Ø³ÙŠØ¯Ø© ÙƒÙ„...          1   \n",
              "4761  4833   ÙŠØ§ Ù…Ø§Ù„ÙŠ Ø¹Ù…Ø±ÙŠ Ø±Ø¶Ø§ ÙŠØ§ Ø´Ø¨ÙŠÙ‡ Ø§Ù„ÙˆØ±Ø¯ , ÙŠØ§ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø­ÙŠ...          1   \n",
              "6564  6707  ÙŠØ§ Ù…Ù† Ø§Ø¸Ù‡Ø± Ø§Ù„Ø¬Ù…ÙŠÙ„.. ÙˆØ³ØªØ± Ø§Ù„Ù‚Ø¨ÙŠØ­.. ÙŠØ§ Ù…Ù† Ù„Ø§ ÙŠÙˆØ§...          1   \n",
              "2753  2760   ÙŠØ§ Ù…ÙƒØ¹Ø¨ Ø§Ù„Ø³ÙƒØ± ÙŠØ§ Ø²Ù…Ø±Ø¯ÙŠ Ø§Ù„Ø§Ø­Ù…Ø± Ùˆ ÙŠØ§Ø³Ø±ÙŠ Ø§Ù„Ø§ÙƒØ¨Ø± ...          1   \n",
              "2124  2125   Ø§Ù„Ù„Ù‡Ù… Ø§Ù†ÙŠ Ø§Ø³Ø§Ù„Ùƒ Ù…Ø³Ø§Ù„Ø© Ø§Ù„Ø¨Ø§ÙŠØ³ Ø§Ù„ÙÙ‚ÙŠØ± ÙˆØ§Ø¯Ø¹ÙˆÙƒÂ Ø¯Ø¹...          0   \n",
              "2434  2441  ÙŠØ§ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠÙŠØ³ ÙŠØ§ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠÙŠØ³ Ù†Ø¹Ù„Ù… Ø§Ù† Ø§Ù„Ø­Ø±Ø¨ ...          0   \n",
              "1399  1400  ÙŠØ§ Ù…Ø±Ø­Ø¨Ø§ ØªØ±Ø­ÙŠØ¨Ø© Ø¹Ù‚Ø§Ø¨ ÙŠØ§ Ù†ÙˆØª ÙˆØ§Ù„Ø­ÙŠ ÙŠÙ„Ø­Ù‚ Ù„Ùˆ ØªØ­Ø¯Ù‡...          1   \n",
              "1880  1881  ÙŠØ§ Ø±Ø§Ø¬Ù„ ÙŠØ§ Ø­Ù…Ø§Ø± Ù‡Ùˆ Ø¹Ù…Ùƒ Ø§Ù„Ø³ÙŠØ³ÙŠ Ù…Ø­ØªØ§Ø¬ Ø¹ÙŠØ§Ù„Ù‡ ÙŠØ¹Ù…Ù„...          0   \n",
              "3050  3122  Ø§Ù†Øª ÙˆØ§Ù…Ø«Ø§Ù„Ùƒ ÙˆØ­ÙƒØ§Ù…Ùƒ ÙˆØ¹Ù„Ù…Ø§ÙŠÙƒ Ø§Ù„Ø²Ù†Ø§Ø¯Ù‚Ù‡ Ø®Ù†Ø§Ø²ÙŠØ± Ø¯Ù…Ø±...          0   \n",
              "\n",
              "      char_count  \n",
              "2922        5627  \n",
              "6062        5251  \n",
              "4761        3097  \n",
              "6564        2190  \n",
              "2753        2079  \n",
              "2124        1069  \n",
              "2434         284  \n",
              "1399         284  \n",
              "1880         283  \n",
              "3050         283  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-669a9528-a288-435c-a494-767c514eb030\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2922</th>\n",
              "      <td>2946</td>\n",
              "      <td>Ù…Ù† Ø§Ù„Ù…Ø¸Ø§Ù‡Ø± Ø§Ù„Ù…ÙˆØ³ÙÙ‡ Ø§Ù† Ø§Ù„Ø§Ø¨ ÙˆØ§Ù„Ø§Ù…  ÙŠÙ‚Ø¹Ø¯ÙˆÙ† ÙŠØªÙ‡Ø§...</td>\n",
              "      <td>1</td>\n",
              "      <td>5627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6062</th>\n",
              "      <td>6160</td>\n",
              "      <td>Ø¬Ø¯Ù‡ Ø§Ù„Ø­Ø¨ ØŒØŒ Ø¬Ø¯Ù‡ ÙŠØ§ Ù…Ù†ØªÙ‡Ù‰ ÙƒÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… ÙŠØ§ Ø³ÙŠØ¯Ø© ÙƒÙ„...</td>\n",
              "      <td>1</td>\n",
              "      <td>5251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4761</th>\n",
              "      <td>4833</td>\n",
              "      <td>ÙŠØ§ Ù…Ø§Ù„ÙŠ Ø¹Ù…Ø±ÙŠ Ø±Ø¶Ø§ ÙŠØ§ Ø´Ø¨ÙŠÙ‡ Ø§Ù„ÙˆØ±Ø¯ , ÙŠØ§ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø­ÙŠ...</td>\n",
              "      <td>1</td>\n",
              "      <td>3097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6564</th>\n",
              "      <td>6707</td>\n",
              "      <td>ÙŠØ§ Ù…Ù† Ø§Ø¸Ù‡Ø± Ø§Ù„Ø¬Ù…ÙŠÙ„.. ÙˆØ³ØªØ± Ø§Ù„Ù‚Ø¨ÙŠØ­.. ÙŠØ§ Ù…Ù† Ù„Ø§ ÙŠÙˆØ§...</td>\n",
              "      <td>1</td>\n",
              "      <td>2190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2753</th>\n",
              "      <td>2760</td>\n",
              "      <td>ÙŠØ§ Ù…ÙƒØ¹Ø¨ Ø§Ù„Ø³ÙƒØ± ÙŠØ§ Ø²Ù…Ø±Ø¯ÙŠ Ø§Ù„Ø§Ø­Ù…Ø± Ùˆ ÙŠØ§Ø³Ø±ÙŠ Ø§Ù„Ø§ÙƒØ¨Ø± ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2124</th>\n",
              "      <td>2125</td>\n",
              "      <td>Ø§Ù„Ù„Ù‡Ù… Ø§Ù†ÙŠ Ø§Ø³Ø§Ù„Ùƒ Ù…Ø³Ø§Ù„Ø© Ø§Ù„Ø¨Ø§ÙŠØ³ Ø§Ù„ÙÙ‚ÙŠØ± ÙˆØ§Ø¯Ø¹ÙˆÙƒÂ Ø¯Ø¹...</td>\n",
              "      <td>0</td>\n",
              "      <td>1069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2434</th>\n",
              "      <td>2441</td>\n",
              "      <td>ÙŠØ§ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠÙŠØ³ ÙŠØ§ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠÙŠØ³ Ù†Ø¹Ù„Ù… Ø§Ù† Ø§Ù„Ø­Ø±Ø¨ ...</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>1400</td>\n",
              "      <td>ÙŠØ§ Ù…Ø±Ø­Ø¨Ø§ ØªØ±Ø­ÙŠØ¨Ø© Ø¹Ù‚Ø§Ø¨ ÙŠØ§ Ù†ÙˆØª ÙˆØ§Ù„Ø­ÙŠ ÙŠÙ„Ø­Ù‚ Ù„Ùˆ ØªØ­Ø¯Ù‡...</td>\n",
              "      <td>1</td>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1880</th>\n",
              "      <td>1881</td>\n",
              "      <td>ÙŠØ§ Ø±Ø§Ø¬Ù„ ÙŠØ§ Ø­Ù…Ø§Ø± Ù‡Ùˆ Ø¹Ù…Ùƒ Ø§Ù„Ø³ÙŠØ³ÙŠ Ù…Ø­ØªØ§Ø¬ Ø¹ÙŠØ§Ù„Ù‡ ÙŠØ¹Ù…Ù„...</td>\n",
              "      <td>0</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>3122</td>\n",
              "      <td>Ø§Ù†Øª ÙˆØ§Ù…Ø«Ø§Ù„Ùƒ ÙˆØ­ÙƒØ§Ù…Ùƒ ÙˆØ¹Ù„Ù…Ø§ÙŠÙƒ Ø§Ù„Ø²Ù†Ø§Ø¯Ù‚Ù‡ Ø®Ù†Ø§Ø²ÙŠØ± Ø¯Ù…Ø±...</td>\n",
              "      <td>0</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-669a9528-a288-435c-a494-767c514eb030')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-669a9528-a288-435c-a494-767c514eb030 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-669a9528-a288-435c-a494-767c514eb030');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Something is weird with these 6 tweets that have 1000+ characters. Those with 281-284 might be explained by my replacing '\\<LF\\>' with a space to keep word boundaries intact, but 1000+ is clearly some kind of data reading error. I'll just remove them."
      ],
      "metadata": {
        "id": "ecDz6UfOjoup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df in dfs:\n",
        "    df.drop(df[df['char_count'] > 1000].index, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "train.sort_values(by='char_count', ascending=[0]).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "tdB6MzdNjlYF",
        "outputId": "0d02f98c-dd12-4a48-eff2-f921a1798e90"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              tweet  subtask_a  \\\n",
              "2433  2441  ÙŠØ§ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠÙŠØ³ ÙŠØ§ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠÙŠØ³ Ù†Ø¹Ù„Ù… Ø§Ù† Ø§Ù„Ø­Ø±Ø¨ ...          0   \n",
              "1399  1400  ÙŠØ§ Ù…Ø±Ø­Ø¨Ø§ ØªØ±Ø­ÙŠØ¨Ø© Ø¹Ù‚Ø§Ø¨ ÙŠØ§ Ù†ÙˆØª ÙˆØ§Ù„Ø­ÙŠ ÙŠÙ„Ø­Ù‚ Ù„Ùˆ ØªØ­Ø¯Ù‡...          1   \n",
              "7190  7358  ÙŠØ§ Ø¹ÙŠØ¨Ø§Ù‡ ÙŠØ§ Ø­Ø³Ø§ÙØ§Ù‡ Ø§Ù„ÙŠÙ…Ù†ÙŠ Ø¨ÙŠÙ‡Ø§Ù† Ø¨ÙƒÙ„ Ù…ÙƒØ§Ù† ÙˆÙ‡Ø°Ø§ ...          1   \n",
              "3047  3122  Ø§Ù†Øª ÙˆØ§Ù…Ø«Ø§Ù„Ùƒ ÙˆØ­ÙƒØ§Ù…Ùƒ ÙˆØ¹Ù„Ù…Ø§ÙŠÙƒ Ø§Ù„Ø²Ù†Ø§Ø¯Ù‚Ù‡ Ø®Ù†Ø§Ø²ÙŠØ± Ø¯Ù…Ø±...          0   \n",
              "1880  1881  ÙŠØ§ Ø±Ø§Ø¬Ù„ ÙŠØ§ Ø­Ù…Ø§Ø± Ù‡Ùˆ Ø¹Ù…Ùƒ Ø§Ù„Ø³ÙŠØ³ÙŠ Ù…Ø­ØªØ§Ø¬ Ø¹ÙŠØ§Ù„Ù‡ ÙŠØ¹Ù…Ù„...          0   \n",
              "6359  6507  Ø¨Ø°Ù„Ø© Ø¹Ø³ÙƒØ±ÙŠØ© ÙˆØ³Ø· Ø§Ù„Ø²Ø­Ø§Ù… .. Ø­ÙŠØ§Ø© Ù…Ù„ÙŠÙŠØ© Ø¨Ø§Ù„Ø§Ø´ÙˆØ§Ùƒ ...          1   \n",
              "3019  3094  Ø§Ù„Ù„Ù‡ ÙŠØ§Ø®Ø°Ùƒ ÙŠØ§ Ø¬Ø§Ù‡Ù„ ÙŠØ§ ØªØ¹Ø¨Ø§Ù† ÙŠØ§ Ù…Ø±ÙŠØ¶ ÙŠØ§ Ù…Ø¹ØªÙˆÙ‡ Ùˆ...          0   \n",
              "475    476  Ø§Ù„Ø±Ø³Ø§Ù„Ù‡ ÙÙŠÙ‡Ø§ Ø¹Ø´Ù… Ù…Ø´ Ø·Ø¨ÙŠØ¹ÙŠ Ø¨Ø³ Ù…Ø´ Ù…Ø´ÙƒÙ„ØªÙŠ. Ø§ÙˆÙ„Ø§ Ùƒ...          0   \n",
              "7612  7780  Ø§Ù„Ù‚ÙŠÙ†Ø§ÙˆÙŠØ© ØºØ§Ù„ÙŠÙŠÙ† Ø¹Ù„ÙŠØ§ Ø§Ø´Ø±ÙÙ‡Ø§ Ù…ÙŠØ© Ù…ÙŠØ© ÙŠØ§ Ø®Ù„Ù‚ ÙŠØ§...          1   \n",
              "2653  2661  Ø§Ù„Ù‡Ù„Ø§Ù„ Ø§Ù…Ø§Ù†Ø© ÙÙŠ ÙŠØ¯ÙŠÙƒÙ… Ø­Ù†Ø§ Ø¹Ù†Ø¯ Ø§Ù„Ù„Ù‡ Ø«Ù… Ø¹Ù†Ø¯ÙƒÙ… Ù‚Ø¨...          1   \n",
              "\n",
              "      char_count  \n",
              "2433         284  \n",
              "1399         284  \n",
              "7190         283  \n",
              "3047         283  \n",
              "1880         283  \n",
              "6359         282  \n",
              "3019         282  \n",
              "475          282  \n",
              "7612         282  \n",
              "2653         282  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d4f0d9d-b6dc-4b90-88c2-f1156d31cfd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2433</th>\n",
              "      <td>2441</td>\n",
              "      <td>ÙŠØ§ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠÙŠØ³ ÙŠØ§ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±ÙŠÙŠØ³ Ù†Ø¹Ù„Ù… Ø§Ù† Ø§Ù„Ø­Ø±Ø¨ ...</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>1400</td>\n",
              "      <td>ÙŠØ§ Ù…Ø±Ø­Ø¨Ø§ ØªØ±Ø­ÙŠØ¨Ø© Ø¹Ù‚Ø§Ø¨ ÙŠØ§ Ù†ÙˆØª ÙˆØ§Ù„Ø­ÙŠ ÙŠÙ„Ø­Ù‚ Ù„Ùˆ ØªØ­Ø¯Ù‡...</td>\n",
              "      <td>1</td>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7190</th>\n",
              "      <td>7358</td>\n",
              "      <td>ÙŠØ§ Ø¹ÙŠØ¨Ø§Ù‡ ÙŠØ§ Ø­Ø³Ø§ÙØ§Ù‡ Ø§Ù„ÙŠÙ…Ù†ÙŠ Ø¨ÙŠÙ‡Ø§Ù† Ø¨ÙƒÙ„ Ù…ÙƒØ§Ù† ÙˆÙ‡Ø°Ø§ ...</td>\n",
              "      <td>1</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3047</th>\n",
              "      <td>3122</td>\n",
              "      <td>Ø§Ù†Øª ÙˆØ§Ù…Ø«Ø§Ù„Ùƒ ÙˆØ­ÙƒØ§Ù…Ùƒ ÙˆØ¹Ù„Ù…Ø§ÙŠÙƒ Ø§Ù„Ø²Ù†Ø§Ø¯Ù‚Ù‡ Ø®Ù†Ø§Ø²ÙŠØ± Ø¯Ù…Ø±...</td>\n",
              "      <td>0</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1880</th>\n",
              "      <td>1881</td>\n",
              "      <td>ÙŠØ§ Ø±Ø§Ø¬Ù„ ÙŠØ§ Ø­Ù…Ø§Ø± Ù‡Ùˆ Ø¹Ù…Ùƒ Ø§Ù„Ø³ÙŠØ³ÙŠ Ù…Ø­ØªØ§Ø¬ Ø¹ÙŠØ§Ù„Ù‡ ÙŠØ¹Ù…Ù„...</td>\n",
              "      <td>0</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6359</th>\n",
              "      <td>6507</td>\n",
              "      <td>Ø¨Ø°Ù„Ø© Ø¹Ø³ÙƒØ±ÙŠØ© ÙˆØ³Ø· Ø§Ù„Ø²Ø­Ø§Ù… .. Ø­ÙŠØ§Ø© Ù…Ù„ÙŠÙŠØ© Ø¨Ø§Ù„Ø§Ø´ÙˆØ§Ùƒ ...</td>\n",
              "      <td>1</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3019</th>\n",
              "      <td>3094</td>\n",
              "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ§Ø®Ø°Ùƒ ÙŠØ§ Ø¬Ø§Ù‡Ù„ ÙŠØ§ ØªØ¹Ø¨Ø§Ù† ÙŠØ§ Ù…Ø±ÙŠØ¶ ÙŠØ§ Ù…Ø¹ØªÙˆÙ‡ Ùˆ...</td>\n",
              "      <td>0</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>476</td>\n",
              "      <td>Ø§Ù„Ø±Ø³Ø§Ù„Ù‡ ÙÙŠÙ‡Ø§ Ø¹Ø´Ù… Ù…Ø´ Ø·Ø¨ÙŠØ¹ÙŠ Ø¨Ø³ Ù…Ø´ Ù…Ø´ÙƒÙ„ØªÙŠ. Ø§ÙˆÙ„Ø§ Ùƒ...</td>\n",
              "      <td>0</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>7780</td>\n",
              "      <td>Ø§Ù„Ù‚ÙŠÙ†Ø§ÙˆÙŠØ© ØºØ§Ù„ÙŠÙŠÙ† Ø¹Ù„ÙŠØ§ Ø§Ø´Ø±ÙÙ‡Ø§ Ù…ÙŠØ© Ù…ÙŠØ© ÙŠØ§ Ø®Ù„Ù‚ ÙŠØ§...</td>\n",
              "      <td>1</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2653</th>\n",
              "      <td>2661</td>\n",
              "      <td>Ø§Ù„Ù‡Ù„Ø§Ù„ Ø§Ù…Ø§Ù†Ø© ÙÙŠ ÙŠØ¯ÙŠÙƒÙ… Ø­Ù†Ø§ Ø¹Ù†Ø¯ Ø§Ù„Ù„Ù‡ Ø«Ù… Ø¹Ù†Ø¯ÙƒÙ… Ù‚Ø¨...</td>\n",
              "      <td>1</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d4f0d9d-b6dc-4b90-88c2-f1156d31cfd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d4f0d9d-b6dc-4b90-88c2-f1156d31cfd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d4f0d9d-b6dc-4b90-88c2-f1156d31cfd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Preprocessing"
      ],
      "metadata": {
        "id": "WU0m50vwjuYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 284\n",
        "\n",
        "def preprocessing_for_bert(data, version=\"mini\"):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-mini-arabic\") if version == \"mini\" else AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "\n",
        "    # For every sentence...\n",
        "    for i, sent in enumerate(data):\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text = sent,\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,             # Max length to truncate/pad\n",
        "            padding='max_length',           # Pad sentence to max length\n",
        "            return_attention_mask=True,     # Return attention mask\n",
        "            truncation = True\n",
        "            )\n",
        "\n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "n_LiOAlijrwc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-test split"
      ],
      "metadata": {
        "id": "tc02E4O9j1rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tt_split(df):\n",
        "    items, labels = df['tweet'], df['subtask_a']\n",
        "    train_items, test_items, train_labels, test_labels = train_test_split(items, labels, test_size=.15, random_state=42)\n",
        "\n",
        "    train_items = train_items.tolist()\n",
        "    train_labels = train_labels.to_numpy()\n",
        "    test_items = test_items.tolist()\n",
        "    test_labels = test_labels.to_numpy()\n",
        "\n",
        "    return train_items, train_labels, test_items, test_labels\n",
        "\n",
        "\n",
        "data_with_emoji = {}\n",
        "data_without_emoji = {}\n",
        "\n",
        "data_with_emoji['train items'], data_with_emoji['train labels'], data_with_emoji['test items'], data_with_emoji['test labels'] \\\n",
        "    = tt_split(train)\n",
        "data_without_emoji['train items'], data_without_emoji['train labels'], data_without_emoji['test items'], data_without_emoji['test labels'] \\\n",
        "    = tt_split(train_no_emoji)"
      ],
      "metadata": {
        "id": "AtTbf53BjvaX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicts = [data_with_emoji, data_without_emoji]\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train and test sets and convert label types to torch.Tensor\n",
        "for d in dicts:\n",
        "    d['train input ids'], d['train masks'] = preprocessing_for_bert(d['train items'])\n",
        "    d['test input ids'], d['test masks'] = preprocessing_for_bert(d['test items'])\n",
        "\n",
        "    d['train labels'] = torch.tensor(d['train labels'])\n",
        "    d['test labels'] = torch.tensor(d['test labels'])"
      ],
      "metadata": {
        "id": "sF8OVAHPj3aE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "2q17uyh3j9aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "## Create the DataLoader for our training set\n",
        "# With emoji:\n",
        "train_data_emoji = TensorDataset(data_with_emoji['train input ids'], data_with_emoji['train masks'], data_with_emoji['train labels'])\n",
        "train_sampler_emoji = RandomSampler(train_data_emoji)\n",
        "train_dataloader_emoji = DataLoader(train_data_emoji, sampler=train_sampler_emoji, batch_size=batch_size)\n",
        "# Without emoji:\n",
        "train_data_no_emoji = TensorDataset(data_without_emoji['train input ids'], data_without_emoji['train masks'], data_without_emoji['train labels'])\n",
        "train_sampler_no_emoji = RandomSampler(train_data_no_emoji)\n",
        "train_dataloader_no_emoji = DataLoader(train_data_no_emoji, sampler=train_sampler_no_emoji, batch_size=batch_size)\n",
        "\n",
        "## Create the DataLoader for our test set\n",
        "# With emoji:\n",
        "test_data_emoji = TensorDataset(data_with_emoji['test input ids'], data_with_emoji['test masks'], data_with_emoji['test labels'])\n",
        "test_sampler_emoji = RandomSampler(test_data_emoji)\n",
        "test_dataloader_emoji = DataLoader(test_data_emoji, sampler=test_sampler_emoji, batch_size=batch_size)\n",
        "# Without emoji:\n",
        "test_data_no_emoji = TensorDataset(data_without_emoji['test input ids'], data_without_emoji['test masks'], data_without_emoji['test labels'])\n",
        "test_sampler_no_emoji = RandomSampler(test_data_no_emoji)\n",
        "test_dataloader_no_emoji = DataLoader(test_data_no_emoji, sampler=test_sampler_no_emoji, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "DBaiJMFoj7PL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the BertClassifier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\" BERT Model for classification tasks. \"\"\"\n",
        "\n",
        "    def __init__(self, freeze_bert=False, version=\"mini\"):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in = 256 if version == \"mini\" else 768\n",
        "        H, D_out = 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = AutoModel.from_pretrained(\"asafaya/bert-mini-arabic\") if version == \"mini\" else AutoModel.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "        # Instantiate a single-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that holds attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "hZwbT3Pqj-r0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(train_dataloader, epochs=4, version=\"mini\"):\n",
        "    \"\"\" Initialize the Bert Classifier, the optimizer and the learning rate scheduler. \"\"\"\n",
        "\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False, version=version)\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(params=list(bert_classifier.parameters()),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    return bert_classifier, optimizer, scheduler\n",
        "\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\" Set seed for reproducibility. \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)"
      ],
      "metadata": {
        "id": "ZS78rh_1kD3v"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, test_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\" Train the BertClassifier model. \"\"\"\n",
        "\n",
        "    # Start training loop\n",
        "    print(\"Starting training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Test Loss':^10} | {'Test Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts += 1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation:\n",
        "            # After the completion of each training epoch, measure the model's performance on our test set.\n",
        "            val_loss, val_accuracy = evaluate(model, test_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\" After the completion of each training epoch, measure the model's performance on our test set. \"\"\"\n",
        "\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the test set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "# With emoji:\n",
        "bert_classifier_emoji, optimizer, scheduler = initialize_model(train_dataloader_emoji, epochs=2)\n",
        "# Without emoji:\n",
        "bert_classifier_no_emoji, optimizer, scheduler = initialize_model(train_dataloader_no_emoji, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvwFp0_HkGQq",
        "outputId": "2905eab7-3b48-47ab-a6c6-fed8e038c4d6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at asafaya/bert-mini-arabic were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "Some weights of the model checkpoint at asafaya/bert-mini-arabic were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('WITH EMOJI:')\n",
        "train(bert_classifier_emoji, train_dataloader_emoji, test_dataloader_emoji, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxH6wK1bkJK3",
        "outputId": "24719c6c-7e68-4230-fbdb-cfa8e49492fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITH EMOJI:\n",
            "Starting training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  | Test Loss  | Test Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.624902   |     -      |     -     |   1.04   \n",
            "   1    |   40    |   0.628832   |     -      |     -     |   0.89   \n",
            "   1    |   60    |   0.634824   |     -      |     -     |   0.89   \n",
            "   1    |   80    |   0.613833   |     -      |     -     |   0.89   \n",
            "   1    |   100   |   0.631339   |     -      |     -     |   0.90   \n",
            "   1    |   120   |   0.631944   |     -      |     -     |   0.89   \n",
            "   1    |   140   |   0.619359   |     -      |     -     |   0.89   \n",
            "   1    |   160   |   0.593919   |     -      |     -     |   0.89   \n",
            "   1    |   180   |   0.616639   |     -      |     -     |   0.90   \n",
            "   1    |   200   |   0.614539   |     -      |     -     |   0.90   \n",
            "   1    |   220   |   0.625242   |     -      |     -     |   0.90   \n",
            "   1    |   240   |   0.614975   |     -      |     -     |   0.90   \n",
            "   1    |   260   |   0.626472   |     -      |     -     |   0.92   \n",
            "   1    |   280   |   0.623026   |     -      |     -     |   0.93   \n",
            "   1    |   300   |   0.623477   |     -      |     -     |   0.93   \n",
            "   1    |   320   |   0.623651   |     -      |     -     |   0.90   \n",
            "   1    |   340   |   0.614521   |     -      |     -     |   0.91   \n",
            "   1    |   360   |   0.624381   |     -      |     -     |   0.90   \n",
            "   1    |   380   |   0.614602   |     -      |     -     |   0.90   \n",
            "   1    |   400   |   0.607125   |     -      |     -     |   0.91   \n",
            "   1    |   416   |   0.632003   |     -      |     -     |   0.71   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.620837   |  0.614600  |   78.50   |   20.12  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  | Test Loss  | Test Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.633167   |     -      |     -     |   0.96   \n",
            "   2    |   40    |   0.615938   |     -      |     -     |   0.92   \n",
            "   2    |   60    |   0.630960   |     -      |     -     |   0.91   \n",
            "   2    |   80    |   0.616564   |     -      |     -     |   0.92   \n",
            "   2    |   100   |   0.632901   |     -      |     -     |   0.92   \n",
            "   2    |   120   |   0.595784   |     -      |     -     |   0.92   \n",
            "   2    |   140   |   0.621757   |     -      |     -     |   0.91   \n",
            "   2    |   160   |   0.626611   |     -      |     -     |   0.92   \n",
            "   2    |   180   |   0.616992   |     -      |     -     |   0.91   \n",
            "   2    |   200   |   0.630431   |     -      |     -     |   0.91   \n",
            "   2    |   220   |   0.634426   |     -      |     -     |   0.93   \n",
            "   2    |   240   |   0.628539   |     -      |     -     |   0.93   \n",
            "   2    |   260   |   0.623545   |     -      |     -     |   0.92   \n",
            "   2    |   280   |   0.614492   |     -      |     -     |   0.92   \n",
            "   2    |   300   |   0.626784   |     -      |     -     |   0.93   \n",
            "   2    |   320   |   0.595610   |     -      |     -     |   0.93   \n",
            "   2    |   340   |   0.617555   |     -      |     -     |   0.93   \n",
            "   2    |   360   |   0.641176   |     -      |     -     |   0.93   \n",
            "   2    |   380   |   0.656982   |     -      |     -     |   0.93   \n",
            "   2    |   400   |   0.611999   |     -      |     -     |   0.93   \n",
            "   2    |   416   |   0.613685   |     -      |     -     |   0.72   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.623253   |  0.614334  |   78.61   |   20.46  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('WITHOUT EMOJI:')\n",
        "train(bert_classifier_no_emoji, train_dataloader_no_emoji, test_dataloader_no_emoji, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0jLdQX7kaYC",
        "outputId": "8ef907ce-37bf-4125-b78e-fdd622779461"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITHOUT EMOJI:\n",
            "Starting training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  | Test Loss  | Test Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.656147   |     -      |     -     |   1.06   \n",
            "   1    |   40    |   0.647950   |     -      |     -     |   1.01   \n",
            "   1    |   60    |   0.674811   |     -      |     -     |   1.02   \n",
            "   1    |   80    |   0.661466   |     -      |     -     |   1.01   \n",
            "   1    |   100   |   0.658689   |     -      |     -     |   1.01   \n",
            "   1    |   120   |   0.645983   |     -      |     -     |   1.02   \n",
            "   1    |   140   |   0.637788   |     -      |     -     |   1.01   \n",
            "   1    |   160   |   0.630856   |     -      |     -     |   1.02   \n",
            "   1    |   180   |   0.640175   |     -      |     -     |   1.02   \n",
            "   1    |   200   |   0.666280   |     -      |     -     |   1.02   \n",
            "   1    |   220   |   0.652334   |     -      |     -     |   1.02   \n",
            "   1    |   240   |   0.658542   |     -      |     -     |   1.30   \n",
            "   1    |   260   |   0.679524   |     -      |     -     |   1.03   \n",
            "   1    |   280   |   0.648173   |     -      |     -     |   1.02   \n",
            "   1    |   300   |   0.660246   |     -      |     -     |   1.03   \n",
            "   1    |   320   |   0.640700   |     -      |     -     |   1.02   \n",
            "   1    |   340   |   0.649543   |     -      |     -     |   1.02   \n",
            "   1    |   360   |   0.655834   |     -      |     -     |   1.02   \n",
            "   1    |   380   |   0.649316   |     -      |     -     |   1.02   \n",
            "   1    |   400   |   0.644598   |     -      |     -     |   1.02   \n",
            "   1    |   416   |   0.652470   |     -      |     -     |   0.79   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.652937   |  0.641452  |   71.79   |   22.78  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  | Test Loss  | Test Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.655923   |     -      |     -     |   1.08   \n",
            "   2    |   40    |   0.641024   |     -      |     -     |   1.01   \n",
            "   2    |   60    |   0.639108   |     -      |     -     |   1.02   \n",
            "   2    |   80    |   0.666882   |     -      |     -     |   1.02   \n",
            "   2    |   100   |   0.646785   |     -      |     -     |   1.01   \n",
            "   2    |   120   |   0.645859   |     -      |     -     |   1.09   \n",
            "   2    |   140   |   0.640177   |     -      |     -     |   1.26   \n",
            "   2    |   160   |   0.663589   |     -      |     -     |   1.18   \n",
            "   2    |   180   |   0.656575   |     -      |     -     |   1.01   \n",
            "   2    |   200   |   0.646139   |     -      |     -     |   1.01   \n",
            "   2    |   220   |   0.633734   |     -      |     -     |   1.01   \n",
            "   2    |   240   |   0.653807   |     -      |     -     |   1.00   \n",
            "   2    |   260   |   0.641957   |     -      |     -     |   1.00   \n",
            "   2    |   280   |   0.649355   |     -      |     -     |   1.00   \n",
            "   2    |   300   |   0.650418   |     -      |     -     |   1.01   \n",
            "   2    |   320   |   0.640422   |     -      |     -     |   1.00   \n",
            "   2    |   340   |   0.648364   |     -      |     -     |   1.00   \n",
            "   2    |   360   |   0.636175   |     -      |     -     |   1.00   \n",
            "   2    |   380   |   0.645399   |     -      |     -     |   1.00   \n",
            "   2    |   400   |   0.663707   |     -      |     -     |   1.00   \n",
            "   2    |   416   |   0.648738   |     -      |     -     |   0.77   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.648306   |  0.641406  |   71.68   |   22.75  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model for future runs\n",
        "pickle.dump(bert_classifier_emoji, open('trained_model_mini_with_emoji.sav', 'wb'))\n",
        "pickle.dump(bert_classifier_no_emoji, open('trained_model_mini_without_emoji.sav', 'wb'))"
      ],
      "metadata": {
        "id": "evfszdHKk0fA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "__j5Ke_iRBzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\" Perform a forward pass on the trained BERT model to predict probabilities on the test set. \"\"\"\n",
        "\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "\n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "AaEoTqBHRCds"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating"
      ],
      "metadata": {
        "id": "PgnJ7rrKRKI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prec_acc(probs, y_true):\n",
        "    preds = probs[:, 1]\n",
        "\n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "\n",
        "    print(f'Accuracy: {accuracy_score(y_true, y_pred) * 100:.2f}%')\n",
        "    print(f'Precision: {precision_score(y_true, y_pred) * 100:.2f}%')\n",
        "    print(f'Recall: {recall_score(y_true, y_pred) * 100:.2f}%')\n",
        "    print(f'f1-score: {f1_score(y_true, y_pred) * 100:.2f}%')\n",
        "\n",
        "\n",
        "# Compute predicted probabilities on the test set\n",
        "probs_emoji = bert_predict(bert_classifier_emoji, test_dataloader_emoji)\n",
        "probs_no_emoji = bert_predict(bert_classifier_no_emoji, test_dataloader_no_emoji)"
      ],
      "metadata": {
        "id": "JMS4QvQ6REmr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('--WITH EMOJI--\\n')\n",
        "calculate_prec_acc(probs_emoji, data_with_emoji['test labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6OcFmuNRMo9",
        "outputId": "5cd62440-90ee-4e30-b366-cd5cd8b8e057"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--WITH EMOJI--\n",
            "\n",
            "Accuracy: 78.72%\n",
            "Precision: 80.14%\n",
            "Recall: 97.66%\n",
            "f1-score: 88.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('--WITHOUT EMOJI--\\n')\n",
        "calculate_prec_acc(probs_no_emoji, data_without_emoji['test labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwKkdtCIRQD-",
        "outputId": "05cb14e4-53d3-4667-c37c-4d27dd72d571"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--WITHOUT EMOJI--\n",
            "\n",
            "Accuracy: 69.02%\n",
            "Precision: 80.10%\n",
            "Recall: 81.63%\n",
            "f1-score: 80.86%\n"
          ]
        }
      ]
    }
  ]
}