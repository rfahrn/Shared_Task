{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jroady_rfahrn_tm_ex05.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "3Sup6WXLW-NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install emoji\n",
        "! pip install pyarabic\n",
        "! pip install transformers"
      ],
      "metadata": {
        "id": "I-uHeaF8XN-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/rfahrn/Shared_Task.git"
      ],
      "metadata": {
        "id": "C9fy7pyiX-8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import unicodedata\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pyarabic.araby as ar\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Z7y8PacKWVWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-mini-arabic\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cnCqwexiWVWr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "train = pd.read_csv('Shared_Task/data/offenseval-ar-training-v1.tsv', sep='\\t')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nJM1mgRNWVWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preview data"
      ],
      "metadata": {
        "id": "ngu1Lp3IaIbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(10)"
      ],
      "metadata": {
        "id": "57aoLZH8aF3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(train.subtask_a)\n",
        "plt.title('Count NOT/OFF')"
      ],
      "metadata": {
        "id": "4pLDsSenaPbM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}